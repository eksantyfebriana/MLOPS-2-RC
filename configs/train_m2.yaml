# Training configuration for Model M2 (Transformer Tiny)
seed: 42
device: auto
batch_size: 16
num_workers: 2
max_epochs: 30
learning_rate: 3.0e-4
weight_decay: 1.0e-4
dropout: 0.2
early_stop_patience: 5
class_weighting: true
scheduler:
  name: cosine
  warmup_epochs: 2
log_interval: 10
val_interval: 1
checkpoint_dir: artifacts/m2
wandb:
  enable: true
  project: slu-mlops
  run_name: m2
augment:
  enable: true
  freq_mask_param: 18
  time_mask_param: 24
  time_shift_max: 12
  noise_std: 0.05
